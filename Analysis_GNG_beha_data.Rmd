---
title: "Analysis_GNG_beha_data"
author: "nomi"
date: "2023-02-20"
output: html_document
---

```{r}
pilot <- read.csv(file = 'pilot.csv')
pilot_dropped <- read.csv(file = 'df.csv') #dropped NAs

View(pilot)
```

#### LOAD LIBRARIES
```{r}
library(tidyverse)
library(BayesFactor)
library(dplyr)
library(rstanarm)
library(lmerTest)
library(GGally)
library(bridgesampling)
library(ggplot2)
library(scales)
library(splines)
library(aod)
library(bridgesampling)
library(tibbletime)
library(yarr)
library(report)
library(sjstats)
library(stats)
library(parsnip)
library(afex)
```


     ####NOTES:
***
#How do I show and interpret the outcome of these:
1. after salient outcomes-feedback (not neutral),participants adjusted their 
   responses to a larger degree following Go responses than NoGo responses
2. When selectively analyzing trials with salient outcomes only, rewards (compared to punishments)
   led to a higher proportion of choice repetitions following Go relative to NoGo responses (valence x response;
valence effect for Go only; valence effect for NoGo 


***Algermissen et al. 2021*** see S02 p.37 Model of stay behavior. 

              QUESTION - not sure how they did it - for the salient - Different datasets?
EFFECT
- Valence                     45.59 1 < .001
- Salience * Valence          30.95 1 < .001
- Action * Valence * Salience 19.73 1 < .001

SALIENT OUTCOME ONLY
- Valence                     46.36 1 < .001
- Action * Valence            17.80 1 < .001

NEUTRAL OUTCOME ONLY
- Action * Valence            12.32 1 < .001


GO with salient outcomes only:
- Valence                     53.93 1 < .001
NOGO with salient outcomes only:
- Valence                     18.23 1 < .001


Mixed-effects logistic regression of 

              QUESTION - unsure about the formulas
A. stay vs. switch behavior 
(i.e., repeating vs. changing an action on the next occurrence of the same cue) 
 as a function of performed action (Go vs. NoGo) (for my dataset is "response"????)

Formula:  ???*response

outcome salience (salient: reward or punishment vs. neutral: no reward or no punishment), 
Formula: ????


outcome valence (positive: reward or no punishment vs. negative: no reward or punishment). 
Formula: ~ valence
Formula: 


salient vs. neutral outcomes separately, 
Formula: 
Formula:

and then separately based on Go vs. NoGo actions(presses) and salient vs. neutral outcomes. 
Formula: response*valence
Formula: response*valence

Pvalues are computed using likelihood ratio tests using the mixed-function (option “LRT”) from package afex.
***
  
  
  

   
     ***Frequentist approach***
   *correct is a binary response (binomial proportion in blocks for example)*


                        **GLMM - correct approach**
              

#all fixed effects
```{r}
pilot_full <- glmer(correct ~ req_action + OutValence  + block + (1|ID), 
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALSE
summary (pilot_full) # block does not seem to affect so I drop it. (add full model as random slop)
#req_actionnoGo -0.90862    0.06823 -13.317  < 2e-16 *** for the requried
report(pilot_full)

pilot_fullt <- glmer(correct ~ req_action + OutValence  + block + TrialCount +(1|ID), 
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALSE
summary (pilot_fullt) # learnigng = trial count p goes up 
```



    ###Learning - main effect of required action Go vs noGo on correct response



#main effect of required action 
```{r}
pilot.m1 <- glmer(correct ~ req_action + (1|ID), 
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot.m1.0 <- glmer(correct ~  + (1|ID),
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


anova(pilot.m1.0, pilot.m1)
summary(pilot.m1)
report::report(pilot.m1)

print(pilot.m1)
coef(pilot.m1)
    
```



********************************************************************************
```{r}
#TRYING TO FIND DEGREES OF FREEDOM - not working but appear in print() and summary (df. red)
lmermodg <- lme4::lmer(correct ~ req_action + (1 + correct||req_action), data=pilot)

afmodr <- mixed(correct ~ req_action + (1 + correct||req_action), data=pilot, check_contrasts = FALSE, test_intercept = TRUE, expand_re = TRUE, method="KR")


#not working
wald.test(b = coef(pilot.m1), Sigma = vcov(pilot.m1), Terms = 2:2)


## odds ratios and 95% CI - not working
exp(cbind(OR = coef(pilot.m1), confint(pilot.m1)))
    

####PSEUDO R-SQUARED FOR LOGISTIC/BINOMIAL - DOES not MAKE SENSE MUCH FOR LOGISTIC
r2_tjur(pilot.m1)#0.1367558 

#########RESIDUALS
plot(pilot.m1,which=1)#If we use R's diagnostic plot, the first one is the 
#scatterplot of the residuals, against predicted values (the score actually)

plot(predict(pilot.m1),residuals(pilot.m1))
abline(h=0,lty=2,col="grey")

#Why do we have those two lines of points ? Because we predict a probability for a variable taking values 0 or 1. If the tree value is 0, then we always predict more, and residuals have to be negative (the blue points) and if the true value is 1, then we underestimate, and residuals have to be positive (the red points). And of course, there is a monotone relationship. We can see more clearly what's going on when we use colors

plot(predict(pilot.m1),residuals(pilot.m1),col=c("blue","red"))
abline(h=0,lty=2,col="grey")

#run a local regression, to see what's going on,
lines(lowess(predict(pilot.m1),residuals(pilot.m1)),col="black",lwd=2)

rl=lm(residuals(pilot.m1)~bs(predict(pilot.m1),8))
#rl=loess(residuals(reg)~predict(reg))
y=predict(rl,se=TRUE)
segments(predict(pilot.m1),y$fit+2*y$se.fit,predict(pilot.m1),y$fit-2*y$se.fit,col="green")


#Predicted probability working but not good
data <- data.frame(actual= pilot$req_action, predicted=predict(pilot.m1))

data$predicted <-as.numeric(data$predicted)

ggplot(data, aes(x=actual, y= predicted)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Actual Values', y='Predicted Values', title='Predicted vs. Actual Values')

ggplot(data=data, aes(x=actual, y=predicted)) +
  geom_point(aes(color=actual), size=4) +
  xlab("req_action") +
  ylab("Predicted probability of being correct") #noGo 64%, Go 81%





                             ***might be helpful***
 #####----> predicted probability shoes much better when results from lmer instead of glmer
            # *****Ignore for others not myself

GLM -Good for the extras...chi, plots, probabilities etc.
https://github.com/StatQuest/logistic_regression_demo/blob/master/logistic_regression_demo.R


logistic <- glm(correct ~ req_action, data = pilot) #famlily= "binomial")
summary(logistic) #requested action is a useful predictor

logistic_0 <- glm(correct ~ 1, data = pilot) 
summary(logistic_0)

anova(logistic, logistic_0)

report::report(logistic)


## Now calculate the overall "Pseudo R-squared" and its p-value
ll.null <- logistic$null.deviance/-2;ll.null
ll.proposed <- logistic$deviance/-2; ll.proposed

## McFadden's Pseudo R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)
(ll.null - ll.proposed) / ll.null # !!!!!OVERAL effect size
## The p-value for the R^2 
1 - pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
 
## chi-square value  
2*(ll.proposed - ll.null) #or


## p-value = 1 - pchisq(chi-square value, df = 2-1)
1 - pchisq(2*(ll.proposed - ll.null), df=1); p=1.20128e-08
1 - pchisq((logistic$null.deviance - logistic$deviance), df=1)


## Lastly, let's  see what this logistic regression predicts, given
## that a patient is either female or male (and no other data about them).
predicted.data <- data.frame(
  probability.of.correct=logistic$fitted.values,
 req_action=pilot$req_action)


## We can plot the data...
ggplot(data=predicted.data, aes(x=req_action, y=probability.of.correct)) +
  geom_point(aes(color=req_action), size=10) +
  xlab("req_action") +
  ylab("Predicted probability of being correct") #noGo 64%, Go 81%

```
********************************************************************************

   
   
    
    ### Biased-responding - responses biased by Cue valence (win/avoid) of prospective outcomes,i.e. favouring win? 
      =  motivational bias -  more presses to win than to avoid

#main effect of CUE valence (WIN OR AVOID) - CORRECT
```{r}
pilot.valence.m1 <- glmer(correct ~ OutValence  + (1|ID), 
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot.m1.0 <- glmer(correct ~  + (1|ID),
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

anova(pilot.m1.0, pilot.valence.m1)
summary(pilot.valence.m1)
report::report(pilot.valence.m1)
print (pilot.valence.m1)

# The effect of cue valence was highly significant 
```




#req_action*valence = their interaction is also significant
```{r}
pilot_rv.m1 <- glmer(correct ~ req_action*OutValence  + (1|ID), 
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot.rv.0 <- glmer(correct ~ req_action + OutValence + (1|ID),
                 data  = pilot, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

anova(pilot.rv.0, pilot_rv.m1)
summary(pilot_rv.m1)
print (pilot_rv.m1)

report::report(pilot_rv.m1)
report::report(pilot.rv.0)

#The effect of cue valence was marginally stronger for the Go cues (Req_ction x Valence). ???oppossite here?????
#Because each Go cue was associated with only one correct Go response, we confirmed that this 
#motivational bias was present for both correct and incorrect Go responses. 
    # How to test the purple????????????? just above?
```


#Feedback was significant only when it is Win or neutral ????????
```{r}
pilot.feed.m1 <- glmer(correct ~ feedback + (1|ID), 
                 data  = pilot, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot.feed.m0 <- glmer(correct ~  + (1|ID), 
                 data  = pilot, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


summary(pilot.feed.m1)
summary(pilot.feed.m0)

anova(pilot.feed.m1, pilot.feed.m0)

report::report(pilot.feed.m0)
report::report(pilot.feed.m1)
```


#Salient outcomes only – rewards led to more choice repetitions following 
GO responses vs. NoGo responses [valence*response] ???NOT clear. the opposite here????

    interaction OutValence*response is significant
```{r}
pilot.or.m1 <- glmer(correct ~ OutValence*response + (1|ID), 
                 data  = pilot, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot.or.m0 <- glmer(correct ~ OutValence + response + (1|ID), 
                 data  = pilot, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(pilot.or.m1)

report::report(pilot.or.m1)

summary(pilot.or.m0)
report::report(pilot.or.m0)
anova(pilot.or.m1, pilot.or.m0 )
```

#Salient outcomes only – rewards led to more choice repetitions following 
GO responses vs. NoGo responses [valence*response] ???NOT clear. 

pilot with NAs (neutral) dropped
```{r}

View(pilot_dropped)
pilot_dr.or.m1 <- glmer(correct ~ OutValence*response + (1|ID), 
                 data  = pilot_dropped, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

pilot_dr.or.m0 <- glmer(correct ~ OutValence + response + (1|ID), 
                 data  = pilot_dropped, family="binomial",
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(pilot_dr.or.m1)

report::report(pilot_dr.or.m1)

summary(pilot_dr.or.m0)
report::report(pilot_dr.or.m0)
anova(pilot_dr.or.m1, pilot_dr.or.m0 )
```

