---
title: "GNG_TUS_Study_1_320trials_ANALYSIS"
author: "nomi"
date: "2023-10-31"
output: html_document
---

#READ FILE
```{r setup, include=FALSE}
library(readr)
tus <- read_csv("GNG_TUS_S1.csv")
View(tus)
```

#Load libraries
```{r}
library(lmerTest)
#library(lMest)
library(dplyr)
library(BayesFactor)
library(leaps)
library(tidyverse)
library(BANOVA)
library (rstan)
library(afex)
library(rstanarm)
library(stringr)
library(report)
library(jtools) #for explanation of lmer
library(emmeans)#2 prefictor, one should be continuous (the "var")
library(effects)
library(lme4)
library(bbmle)
library(MASS)
library(MuMIn)
library(AICcmodavg)#https://www.scribbr.com/statistics/akaike-information-criterion/#:~:text=Once%20you've%20created%20several,be%20the%20better%2Dfit%20model.
#help to interpret results from AICmodavg
```

#Analysis

  ##Accuracy

   
      #comparing glmer models - Logistic regression
             ####???Should check for multicollinearity by calculating a Variance Inflation Factor (VIF) for each independent variable maybe?

```{r}

#Equivalent of stepAIC for glmer - comparing models - do not like it

      #WAY_1
# List of fixed effects
fixed_effects <- c("OutValence", "req_action", "condition", "trial_number")

# Generate all possible combinations of two-way interactions
interaction_terms_2way <- combn(fixed_effects, 2, simplify = FALSE) %>%
  lapply(function(x) paste(x, collapse = "*"))

# Generate all possible combinations of three-way interactions
interaction_terms_3way <- combn(fixed_effects, 3, simplify = FALSE) %>%
  lapply(function(x) paste(x, collapse = "*"))

# Combine two-way and three-way interaction terms
interaction_terms <- c(interaction_terms_2way, interaction_terms_3way)

# Check if there are valid combinations
if (length(interaction_terms) == 0) {
  cat("No valid combinations of interactions found.")
} else {
  # List to store models and AIC values
  model_list <- list()
  
  # Loop through each combination of interactions and fit models
  for (i in seq_along(interaction_terms)) {
    # Create formula string with interactions and random intercept
    formula_str <- as.formula(paste("correct ~", interaction_terms[[i]], "+ (1|ID)"))
    
    # Fit the model
    tryCatch({
      temp_model <- glmer(formula_str, data = tus, family = "binomial",
                          glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000)))
      
      # Calculate AIC and store the model
      temp_AIC <- AIC(temp_model)
      model_list[[interaction_terms[[i]]]] <- list(model = temp_model, AIC = temp_AIC)
    }, error = function(e) {
      cat("Error occurred with this formula:", deparse(formula_str), "\n")
    })
  }
  
  # Order models by AIC value
  ordered_models <- model_list[order(sapply(model_list, function(x) x$AIC))]
  
  # Print the ordered models
  print(ordered_models)
}


        #WAY_2


# Step 1: Fit a series of GLM models (good models without the overfitted: 4 and 9 is decent 8, 7, 6, 3, 1 (5 nearly unidentifiable))

        #all main effects are significant 
model1 <- glmer(correct ~ OutValence + req_action + condition +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
        #all main effects are significant
model2 <- glmer(correct ~ OutValence + req_action + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#all main effects and interaction is significant. val*req_action = Cue
model3 <- glmer(correct ~ OutValence * req_action + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model4 <- glmer(correct ~ OutValence * req_action * condition +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#this is probably the one!

model0 <- glmer(correct ~condition + req_action + condition*req_action + OutValence + condition*OutValence + req_action*OutValence +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model0)#ignore most probably
model5 <- glmer(correct ~ OutValence * req_action * condition * trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
model6 <- glmer(correct ~ Cue + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model7 <- glmer(correct ~ Cue + condition + OutValence + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model8 <- glmer(correct ~ Cue * condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model9 <- glmer(correct ~ Cue * condition * trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model9)#not 9
model10 <- glmer(correct ~ Cue * condition * OutValence* req_action* trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model10)
model11 <- glmer(correct ~  OutValence * req_action *condition * trial_number + RT + (1|ID) ,
                   data = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model11)#not11
model12 <-glmer(correct ~ OutValence + req_action + condition + RT +trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model13 <-glmer(correct ~ OutValence + req_action + condition + RT +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model14 <- glmer(correct ~ OutValence + req_action + condition + trial_number + (OutValence * req_action * condition * trial_number) + (1|ID) ,        
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))); summary (model14) #REML = FALSE
#overfit i think 14, but also OutValenceWin:conditionc.ai:trial_number                  -0.0050235  0.0013815  -3.636 0.000277 ***
model15 <- glmer(correct ~ req_action + OutValence + trial_number + condition +(1|ID) + ( req_action + OutValence + trial_number + condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#no 15
model16 <- glmer(correct ~ req_action * OutValence + trial_number + condition +(1|ID) + ( req_action * OutValence + trial_number + condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
 #takes ages and crashes
model17 <- glmer(correct ~ req_action * OutValence * trial_number * condition +(1|ID) + ( req_action * OutValence * trial_number * condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model18 <- glmer(correct ~ req_action + OutValence + trial_number + condition +RT +(1|ID) + ( req_action * OutValence * trial_number * condition +RT|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model19 <- glmer(correct ~ req_action * OutValence * trial_number * condition *RT +(1|ID) + ( req_action * OutValence * trial_number * condition *RT|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE


#model 20 not working atm
# Identify non-numeric columns
non_numeric_cols <- c("req_action", "OutValence", "trial_number", "condition", "RT")

# Convert non-numeric values to NA
tus[, non_numeric_cols] <- lapply(tus[, non_numeric_cols], function(x) {
  as.numeric(as.character(x))
})

# Replace missing values with column means
tus[, non_numeric_cols] <- lapply(tus[, non_numeric_cols], function(x) {
  ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})

# Scale numeric columns
scaled_tus <- tus
scaled_tus[, non_numeric_cols] <- scale(tus[, non_numeric_cols])

# Check the class of ID column
class(scaled_tus$ID)

# Convert ID to factor if it's not already a factor
if (!is.factor(scaled_tus$ID)) {
  scaled_tus$ID <- as.factor(scaled_tus$ID)
}

model20 <- glmer(correct ~ req_action * OutValence * trial_number * condition * RT + (1|ID),
                 data = scaled_tus, family = binomial,
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))




# Step 2: Create a data frame with model names and AIC values
models_data <- data.frame(
  Model = c("model1", "model2", "model3", "model4", "model5", "model6", "model7", "model8", "model9", "model10", "model11", "model12",  "model13", "model14"),#, "model15", "model16", "model17", "model18", "model19"),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6), AIC(model7), AIC(model8), AIC(model9), AIC(model10), AIC(model11), AIC(model12), AIC(model13), AIC(model14)))
  
  #, #AIC(model15), AIC(model16), AIC(model17), AIC(model18), AIC(model19)))
                          

models_data$AIC <- as.numeric(models_data$AIC)
# Step 3: Order the data frame based on AIC values
models_data <- models_data[order(models_data$AIC), ]


# Step 4:Output the ordered models and AIC values
cat("Ordered AIC values:\n")
print(models_data)


      #OR preferable
# Step 2: Compare models using aictab
# Create the AIC table
aictab_result <- aictab(cand.set = list(model1, model2, model3, model4, model5, model11, model12, model13))#, model14, model15, model16, model17, model18, model19),
  modnames = c("model1", "model2", "model3", "model4", "model5",  "model11", "model12", "model13")#, "model14", "model15", "model16", "model17", "model18", "model19"))

# Step 3: Reorder the AIC table by AICc values
aictab_result <- aictab_result[order(aictab_result$AICc), ]

# Step: 4Print the reordered AIC table
print(aictab_result)

```

#Summary models above
```{r}
# Assuming you have a list of 10 models named model1, model2, ..., model10
model_list <- list(model1, model2, model3, model4, model5, model11, model12, model13)

# Use lapply to get summaries for all models
model_summaries <- lapply(model_list, summary)

# Now you can access each summary using model_summaries[[1]], model_summaries[[2]], and so on
model_summaries[[0]]
```

```{r}
# do not hot to combine the allmeans or alleffects to check the beta basic level main effects.
```

#Plotting the effects? Help - NOT WORKING
```{r}
#Not sure how to interpret the model (whichever I pick) or how to plot:
acc <- allEffects(model_acc, xlevels=list(req_action=seq(0, 24, 6)),
                   fixed.predictors=list(given.values=c(OutValenceWin =0.5)));acc

as.data.frame(acc[[]])

# the following are equivalent:
eff.ne <- effect("OutValence*req_action", model_acc)
Eff.ne <- Effect(c("OutValence", "req_action"), model_acc)
all.equal(eff.ne$fit, Eff.ne$fit)

# Assuming you have extracted the estimated effects into a data frame
# For example, using as.data.frame(eff.cowles[[2]])-->
# Create a ggplot object - not working yet
acc<-as.data.frame(acc)
ggplot(data =acc, aes(x = req_action, y = fit)) +
  geom_point() +  # Add points to the plot
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +  # Add error bars
  labs(x = "req_action", y = "Effect") +  # Label the axes
  ggtitle("Estimated Effects of req_action")  # Add a title

#or  #not working either - i do not know
plot(acc, 'OutValence', axes=list(grid=TRUE,
y=list(lab="condition"),
x=list(rotate=90)),
lines=list(lty=0))
```


#run anovaBF (not the correct analysis as the DV is categorical - just trying)
```{r}
#drop NAs
df <- na.omit(tus)
df$ID <- as.factor(df$ID)
df$correct <- as.integer(df$correct)
df$req_action <- as.factor(df$req_action)
df$condition <- as.factor(df$condition)
df$trial_number <- as.factor(df$trial_number)
df$OutValence <- as.factor(df$OutValence)
df$Cue <- as.factor(df$Cue)


#anovaBF IV = req_action
 accu <-anovaBF(correct ~ OutValence*req_action*condition*trial_number  + ID, data = df, whichRandom = "ID",
   progress=FALSE); accu
accu[17]/accu[12]
accu/max(accu)#best models as denominator to so the closest ones

#anovaBF IV = Cue - interaction between the Cue and the condition
accu_cue <-anovaBF(correct ~ Cue*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
accu_cue[4]/accu_cue[3]
lm(RT ~ condition +req_action +OutValence, data=tus)



#banova!!!!!!!! - not working atm
# Making sure JAGS is installed
# It can be downloaded here http://mcmc-jags.sourceforge.net (the size is only 2.3 MB)

BANOVA::BANOVA.run (correct ~ req_action, ~condition*req_action, data=df, model_name = 'Binomial', id = 'ID',
                        as.integer(16), num_trials = as.integer(20), iter = 100, thin = 5, chains = 2)
```

#RTs

#fit-and-bic equivalent of stepAIC for lmer
```{r}
# Function to create all combinations of predictors including interactions up to four variables
get_combinations <- function(predictors) {
  n <- length(predictors)
  combs <- unlist(lapply(1:n, function(i) combn(predictors, i, simplify = FALSE)), recursive = FALSE)
  
  # Generate combinations with interactions up to four variables
  interactions_4way <- lapply(1:(n-3), function(i) {
    combn(predictors, i, FUN = function(x) {
      remaining <- setdiff(predictors, x)
      combs <- combn(remaining, 3, paste, collapse = "*")
      paste(x, combs, sep = "*")
    })
  })
  
  interactions_4way <- unlist(interactions_4way, recursive = FALSE)
  
  c(combs, interactions_4way)
}

# Function to fit models and compute BIC, excluding redundant models
fit_and_bic <- function(data, response, predictors) {
  combinations <- get_combinations(predictors)
  bics <- numeric(length(combinations))
  
  for (i in seq_along(combinations)) {
    formula <- as.formula(paste(response, "~", paste(combinations[[i]], collapse = " + "), "+ (1|ID)"))
    model <- lmer(formula, data = data, REML = FALSE)
    bics[i] <- BIC(model)
  }
  
  result <- data.frame(Model = sapply(combinations, paste, collapse = " + "), BIC = bics)
  result <- result[order(result$BIC), ]
  
  # Remove redundant models
  result <- result[!duplicated(lapply(strsplit(result$Model, "\\+"), function(x) sort(trimws(x)))), ]
  
  result
}

# Define your response variable and predictor variables
response_var <- "RT"
predictor_vars <- c("OutValence", "req_action", "condition", "trial_number")

# Example usage
result <- fit_and_bic(data = tus, response = response_var, predictors = predictor_vars)
print(result)
```


#comparing between three model. This looks to be the best "model_rt_tn" (model 2 and 3)
```{r}
model_rt1 <- lmer(RT ~ req_action*OutValence*condition +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt1) 

model_rt2 <- lmer(RT ~ OutValence*req_action*condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt2)#THIS MODEL seems to be the best

#model_rt_tnsn<- lmer(RT ~ req_action*OutValence*condition*trial_number*session +(1|ID), data  = tus, REML = FALSE) 
#summary (model_rt_tnsn) # NO

model_rt3 <- lmer(RT ~ OutValence*req_action*condition +trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt3) # good

model_rt4 <- lmer(RT ~ req_action*OutValence*condition +  condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt4) #good too

model_rt5 <- lmer(RT ~ req_action*OutValence +  condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt5)#
   
# Perform Likelihood Ratio Test
lr_test <- anova(model_rt1, model_rt2, model_rt3, model_rt4, model_rt5)
print(lr_test) 
p_value <- lr_test$Pr[2];p_value
```

#anovaBF for RTs
```{r}
#run anovaBF IV = req_action and condition
 rt <-anovaBF(RT ~ req_action*OutValence*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
rt[17]/rt[13] 
 rt[18]/rt[13] 
 rt[18]/rt[17] 
summary(rt)
ratios<-rt/max(rt);ratios#best models as denominator to so the closest ones 13, 14, 15, 17, 18, 16, 12, 11



#or
# Remove rows with missing values in 'RT'
tus <- na.omit(tus)
# Convert 'ID' to factor if it's not already a factor
if (!is.factor(tus$ID)) {
  tus$ID <- as.factor(tus$ID)
}

# Calculate Bayes factors for each model using the 'tus' dataset
bf_13 <- lmBF(RT ~ req_action + OutValence + req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_15 <- lmBF(RT ~ condition + req_action + condition:req_action + OutValence + req_action:OutValence + condition:req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_17 <- lmBF(RT ~ condition + req_action + condition:req_action + OutValence + condition:OutValence + req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_18 <- lmBF(RT ~ condition + req_action + condition:req_action + OutValence + condition:OutValence + req_action:OutValence + condition:req_action:OutValence + ID, data = tus, whichRandom = "ID")

# Extract Bayes factors
bf_values <- c(bf_13, bf_15, bf_17, bf_18)

# Compare Bayes factors
bf_values / max(bf_values)

```



#Reporting -  examples
```{r}
summ(model_acc, exp = T)# set "exp = T" to show esponentiated estimates; if you need standardised estimaets, set "scale = T"
summ(model_acc, scale = T)
report(model_acc)
report(model_acc) %>% summary()
report_table(model_acc)
report_performance(model_acc)
report_parameters(model_acc)
```
 
#########################################################################################################################################################################################


          #from here ONWARDS, IT CAN BE IGNORED AT THE MOMENT - DECIDE IF NEEDED
          
          #Cue  - not needed
```{r}
model_rt_cue <- lmer(RT ~ Cue*condition +(1|ID) , 
                 data  = tus,REML = FALSE) #REML = FALSE
summary (model_rt_cue)

#anovaBF IV = Cue - interaction between the Cue and the condition
rt_cue <-anovaBF(RT ~ Cue*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
rt_cue[4]/rt_cue[3]
summary(rt_cue)
```

  # ANALYSIS FOR SALIENT ONLY (EXCLUDE NEUTRAL OUTCOME)
  
```{r}
#select salient only (win, lose) and keep variables ID through block and all columns between them
tus_salient <- subset(tus, salient=!"neutral",
select=ID:salient);  

salient_df <-tus_salient %>% drop_na();  View(salient_df) # WRONG IT DRPOPS ACC AS WELL
```  

        
## Accuracy
```{r}
model_acc_sal <- glmer(correct ~ condition + req_action + trial_number + OutValence*condition + req_action*condition +(1|ID) , 
                 data  = salient_df, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALS
summary(model_acc_sal)

#Cue impact - not good
sal_cue_accu <- glmer(correct ~ Cue*condition*trial_number +(1|ID) , 
                 data  = salient_df, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALSE
summary (sal_cue_accu) 
```

## RTs
```{r}
model_rt_sal <- lmer(RT ~ req_action  + trial_number + OutValence*condition + req_action*condition+(1|ID), 
                 data  = salient_df, REML = FALSE) #REML = FALSE
summary (model_rt_sal) 
report_table(model_rt_sal)
#Cue impact -that is good
sal_cue_rt <- lmer(RT ~ Cue*condition +(1|ID), 
                 data  = salient_df, REML = FALSE) #REML = FALSE
summary (sal_cue_rt) 
```


 ##Analysis with Bayesian binomial/logistic anova for the categorical DV - "correct"
      # with rstarm + bridging

```{r}

library(htmltools)
options(mc.cores = 4)


cor.m1.stan <- rstanarm::stan_glmer(correct ~ condition * OutValence * req_action * Cue + (1|ID),  weights=trial_number,
                 data  = tus, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df1.csv") #deleted the "weights = ..."

cor.m1.0.stan <- rstanarm::stan_glmer(correct ~ (condition + OutValence + req_action) * Cue + (1|ID), weights=trial_number,
               data  = tus, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df0.csv") #notsure if this the base model. #deleted the "weights = ..."

bridge_1 <-bridgesampling::bridge_sampler(cor.m1.stan)
bridge_0 <- bridgesampling::bridge_sampler(cor.m1.0.stan)
# BW: this gives evidence (or not) for the interaction
bayes_factor(bridge_1, bridge_0, log = FALSE)



##model with no interaction 
acc.m2.stan <- rstanarm::stan_glmer(is_slip ~ condition * Cue + (1|ID), 
               data  = elm_test.byblock, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df2.csv")

acc.m3.0.stan <- rstanarm::stan_glmer(is_slip ~ condition + Cue + (1|ID), 
                weights=exposure, data  = elm_test.byblock, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df2.0.csv")

bridge_3 <-bridgesampling::bridge_sampler(acc.m2.stan)
bridge_3.0 <- bridgesampling::bridge_sampler(acc.m3.0.stan)


# evidence
bayes_factor(bridge_3, bridge_3.0, log = FALSE)

```

