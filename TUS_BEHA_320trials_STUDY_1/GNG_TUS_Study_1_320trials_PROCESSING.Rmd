---
title: "GNG_TUS_Study_1_320trials_PROCESSING"
author: "nomi"
date: "2023-10-31"
output: html_document
---

#READ FILE
```{r setup, include=FALSE}
library(readr)
tus <- read_csv("GNG_TUS_S1.csv")
View(tus)
```

#Load libraries
```{r}
library(tibbletime)
library(purrr)
library(stringr)
library(report)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(patchwork)
library(ggpubr)
library(yarr)
library (yarrr)
library(afex)
#install.packages("devtools")
#devtools::install_github("mikabr/ggpirate")
library(ggpirate)
```

 #APA theme
```{r}
theme_APA <- theme_bw()+
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          axis.line = element_line(linewidth = 1),                                        
          text = element_text(
              size = 20,
              face="bold"), 
          axis.text = element_text(
              size = 20,
              face="plain",
              colour="black"),
          legend.title = element_blank(),
          legend.position = 'top',
          legend.direction = "horizontal",
          legend.text = element_text(
              face="plain",
              colour="black",
              size=20),
          strip.text.x = element_text(
              size = 20,
              face = "bold"),
          panel.background = element_rect(
              fill='white',
              colour='white'),
          strip.background = element_rect(
              fill='white',
              colour='white'),
          axis.title.x = element_text(
              margin = margin(t = 10)),
          plot.margin = grid::unit(c(5, 5, 5, 5), "mm"),
          plot.caption = element_text(size=15)
          )
```

 
 #PROCESSING


## MEAN RT - PRESSES 
```{r}
tus_presses <- subset(tus, RT != "0") # exlude 0s (no presses)
RT_presses <-tus_presses%>%  group_by(condition) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
RT_presses_many_variables <-tus_presses %>%  group_by(condition, req_action, correct, response) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
```

## MEAN CORRECT
```{r}
correct_res <-tus%>%  group_by(condition, ID) %>% 
  summarise(correct = mean(correct))
RT_presses_many_variables <-tus_presses %>%  group_by(condition, req_action, correct, response) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
```

## Distribution of RT
```{r}
tus_presses <- subset(tus, RT != "0") # exlude 0s (no presses)
RT_presses <-tus_presses%>%  group_by(RT, ID) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE));RT_presses #%>%
ggplot(data = RT_presses, 
       aes(x = Mean_RT)) + 
  geom_histogram()+ ggtitle ("Distribution of RT for presses") +theme_APA

#mean RT per participant
MeanRTpersub <- tus %>% filter(response == "press")%>% group_by(Cue, ID, req_action, OutValence,condition) %>% summarise(RT = mean(RT))

yarrr::pirateplot(formula = RT ~ req_action + OutValence + condition,    # DV = reaction time, IV1 = required action, IV2 = outcome valence
                  data = MeanRTpersub,           
                  theme = 2,
                 # main = "Condition",
                  ylab = "Reaction Time (ms)",
                  ylim = c(400, 1000),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7) + theme_APA
```

## Proportion of GO response per condition 
**two participants have 21-22 or 23 trials of a Cue- NOT SURE why?.Also NAs count as over 20 trial, but omitted here.**
```{r}
# compute proportion of go responses for each participant (first sum per ID, then feed that into general summary)
MeanGoResppersub <- tus %>% group_by(ID, Cue, req_action, OutValence, block, TrialCount) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub <- na.omit(MeanGoResppersub)
MeanGoResp <- MeanGoResppersub %>% group_by(Cue, req_action, block, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

#plot of p(Go) responses 
ggplot(MeanGoResp) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
  xlim (0,20) +theme_bw() 
#plot of p(Go) responses per block
ggplot(MeanGoResp) + 
  geom_smooth(aes(TrialCount,GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  facet_grid(~block)+
  theme_bw() +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
  xlim(0, 20)
```


## Session 
### It seems to be significant. In the first session they do worse.
```{r}
# compute proportion of correct responses for each participant
tus_correct_sub <- tus %>% group_by(ID, OutValence,session,  condition, req_action) %>% summarise(correct = mean(correct))
# compute mean proportion of go responses 
tus_correct <- tus_correct_sub %>% group_by(OutValence, session, req_action, condition) %>% summarise(correct = mean(correct))


#plot session

  #re-ordering levels to show as 1,2,3 in the x-axis
tus_correct$session <- factor(tus_correct$session, levels = c("1", "2", "3"))

pirateplot(formula = correct ~ session +condition,
           data = tus_correct,
                           theme = 0,
           #main = "Fully customized pirateplot",
           #pal = "southpark", # southpark color palette
           bean.f.o = .7, # Bean fill
           point.o = .3, # Points
           inf.f.o = .3, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+theme_APA
         # ylim = c(0.1, 1.0))

#without "condition"
pirateplot(formula = correct ~ session,
           data = tus_correct,
           theme = 0,
           bean.f.o = .7,
           point.o = .3,
           inf.f.o = .3,
           inf.b.o = .8,
           avg.line.o = 1,
           bar.f.o = .5,
           inf.f.col = "white",
           inf.b.col = "black",
           avg.line.col = "black",
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7) + theme_APA
```


#proportion of GO response per type of Stimulation (sham, ai, dACC) - NADEIDE  and ELSA to check
```{r}
    #AI - 
ai <- subset(tus, condition == "c.ai")

# compute proportion of go responses for each participant
MeanGoResppersub_ai <- ai %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

MeanGoResp.ai <- MeanGoResppersub_ai %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

#plot
ai_rolavg<- ggplot(MeanGoResp.ai) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for AI") +
   xlim(NA, 20)+
 theme_bw() 


    #dACC - 
dacc <- subset(tus, condition == "b.dacc")
#dacc <- na.omit(dacc)

# compute proportion of go responses for each participant
MeanGoResppersub_dacc <- dacc %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResp.dacc <- MeanGoResppersub_dacc %>% group_by(Cue, req_action, OutValence, TrialCount ) %>% summarise(GoResponse = mean(GoResponse))

#plot
dacc_rolavg<- ggplot(MeanGoResp.dacc) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for dACC")+
   xlim(NA, 20)+ theme_bw() 



    #Sham
sham <- subset(tus, condition == "a.sham")

# compute proportion of go responses for each participant
MeanGoResppersub_sham <- sham %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

MeanGoResp.sham <- MeanGoResppersub_sham %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

#plot
sham_rolavg<- ggplot(MeanGoResp.sham) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for sham") +
   xlim(NA, 20)+
 theme_bw() 

#roll avg per CONDITION
rol_avg <- ggarrange(sham_rolavg, ai_rolavg, dacc_rolavg,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);rol_avg



```

##rolling average per CUE for all three conditions (plot with NGW for three conditions (sham, ai, dACC), plot GW..etc.)

  ***it looks like stimulation to ACC increases the propensity to press in the Go condition. And STIM to both areas slows down learning in the noGO condition***
```{r}
#Grey area is CI

#GW
GW <- subset(tus, Cue == "GW")

# compute proportion of go responses for each participant
MeanGoResppersub_gw <- GW %>% group_by(ID, req_action, OutValence, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_gw <- na.omit(MeanGoResppersub_gw)
MeanGoResp_gw <- MeanGoResppersub_gw %>% group_by(req_action, OutValence, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot######################play with lines
GW<-ggplot(data=MeanGoResp_gw, mapping =aes(TrialCount, GoResponse, colour=condition)) + 
  geom_smooth(linetype = "longdash") +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
  ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_GW") +theme_bw() 

#GAL
GAL <- subset(tus, Cue == "GAL")

# compute proportion of go responses for each participant
MeanGoResppersub_gal <- GAL %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_gal <- na.omit(MeanGoResppersub_gal)
MeanGoResp_gal <- MeanGoResppersub_gal %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot
GAL<-ggplot(data=MeanGoResp_gal, mapping =aes(TrialCount, GoResponse, colour=condition)) + 
  geom_smooth(linetype = "longdash") +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_GAL") +theme_bw() 

#NGW
NGW <- subset(tus, Cue == "NGW")

# compute proportion of go responses for each participant
MeanGoResppersub_NGW <- NGW %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_NGW <- na.omit(MeanGoResppersub_NGW)
MeanGoResp_NGW <- MeanGoResppersub_NGW %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot - need to work on linetype
NGW<-ggplot(MeanGoResp_NGW) + 
  geom_smooth(aes(TrialCount, GoResponse, colour=condition )) +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_NGW") +theme_bw() 



#NGW
NGL <- subset(tus, Cue == "NGL")

# compute proportion of go responses for each participant
MeanGoResppersub_NGL <- NGL %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_NGL <- na.omit(MeanGoResppersub_NGL)
MeanGoResp_NGL <- MeanGoResppersub_NGL %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot
NGL<-ggplot(MeanGoResp_NGL) + 
  geom_smooth(aes(TrialCount, GoResponse, colour=condition )) +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
      ylim(0.05, 0.9)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_NGL") + theme_bw() 


# Determine the maximum and minimum values of GoResponse, cause NGL depricated
max_response <- max(c(MeanGoResp_gw$GoResponse, MeanGoResp_gal$GoResponse, MeanGoResp_NGW$GoResponse, MeanGoResp_NGL$GoResponse))
min_response <- min(c(MeanGoResp_gw$GoResponse, MeanGoResp_gal$GoResponse, MeanGoResp_NGW$GoResponse, MeanGoResp_NGL$GoResponse))

# Set the y-axis limits with a buffer for error bars
y_min <- min_response - 0.1  # Adjust the buffer as needed
y_max <- max_response + 0.0  # Adjust the buffer as needed

# Update the y-axis limits for all plots
GW <- GW + ylim(y_min, y_max)
GAL <- GAL + ylim(y_min, y_max)
NGW <- NGW + ylim(y_min, y_max)
NGL <- NGL + ylim(y_min, y_max)

# Combine the plots
cues <- ggarrange(GW, GAL, NGW, NGL, ncol = 2, nrow = 2)
cues

```


## Probability of correct per participant ***IS THAT CORRECT?***
```{r}
tus_correct<-tus %>%  group_by(ID, OutValence,condition, req_action) %>% summarise(correct = mean(correct))
tus_correct_sub_gen <- tus_correct %>% group_by(OutValence, req_action, condition) %>% summarise(correct = mean(correct))
tus_correct_sub_gen<-na.omit(tus_correct_sub_gen)
yarrr::pirateplot(formula = correct ~ condition  +req_action +OutValence,    
                  data = tus_correct,           
                  theme = 2,
                 #main = "Proba_correct/condition",
                  ylab = " (p) of correct",
                  ylim = c(0.1, 1.15),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7)

##maybe this to be the same as the RTs
yarrr::pirateplot(formula = correct ~  req_action + OutValence + condition,    
                  data = tus_correct,           
                  theme = 2,
                 # main = "Condition",
                  ylab = "(p) of correct",
                  ylim = c(0,1),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7)  + facet_grid(~condition) + theme_APA 


#not workinh --> empty
#or per all, per ID (mean of means) --> NULL = probably not correct thing for pirate plot
yarrr::pirateplot(formula = correct ~  req_action + OutValence + condition,    
                  data = tus_correct_sub_gen,           
                  theme = 2,
                 # main = "Condition",
                  ylab = "(p) of correct per Sub",
                  ylim = c(0.4,1.15),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7)  + 
                  facet_grid(~condition) + theme_APA 



#or --> no error bars
# Calculate mean and standard error per condition
# Calculate mean and standard error per condition and req_action
summary_data <- tus_correct_sub_gen_filtered %>%
  group_by(condition, req_action, OutValence) %>%
  summarise(mean_correct = mean(correct),
            se_correct = sd(correct, na.rm = TRUE) / sqrt(n()))

# Plot with error bars
ggplot(summary_data, aes(x = req_action, y = mean_correct, fill = OutValence)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_correct - se_correct, ymax = mean_correct + se_correct),
                position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~ condition) +
  labs(title = "Mean Correct with Standard Error bars_noGo") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability




```

# ACCURACY PLOTS (x6)
### proportion of correct per participant per condition ***IMPORTANT FOR THE GW FOR THE AI***

```{r}
# 1. compute proportion of go responses for each participant <- same as aboe I think
tus_correct_sub <- tus %>% group_by(ID, OutValence, condition, req_action) %>% summarise(correct = mean(correct))
# compute mean proportion of go responses 
tus_correct_meaned <- tus_correct_sub %>% group_by(OutValence, req_action, condition) %>% summarise(correct = mean(correct))


pirateplot(formula = correct ~ condition  + req_action +OutValence,
           data = tus_correct_meaned,
           theme = 1,
           #main = "Accuracy",
           #labs(y = "correct (accuracy)") ,
           bar.f.o = .5, 
           point.o = .5, 
          ylim = c(0.5, 1.0))+theme_APA

# 2.THE SAME AS ABOVE 
pirateplot(formula = correct ~ condition  + OutValence +req_action,
           data = tus_correct_meaned,
                           theme = 0,
           #main = "Fully customized pirateplot",
           #pal = "southpark", # southpark color palette
           bean.f.o = .6, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+ theme_APA

# 3. same with stat_summary
tus_correct <- na.omit(tus_correct)

tus_acc_plot <-ggplot(data=tus_correct, aes( x=condition, y=correct, fill=condition))+  
  stat_summary(fun.y = mean, geom = "bar") + 
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.3); tus_acc_plot

 tus_acc_plot + facet_grid(req_action ~ OutValence) + theme_APA 


 #TRYING ADDING ERROR BARS AS i CANNOT DO IT WITH THE ABOVE CODE

# 4. Calculate summary statistics (mean and standard deviation)

ppts<-tus %>% group_by(ID) %>%
   distinct(ID) %>% 
  nrow() # number of participants

MeanGoResppersub_cond <- tus %>% group_by(ID, Cue, req_action, OutValence, block, TrialCount, condition, correct) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_cond <- na.omit(MeanGoResppersub_cond)
#MeanGoResppersub_cond <- MeanGoResppersub_cond %>% group_by(Cue, req_action, block, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

summary_data <- MeanGoResppersub_cond %>%
  group_by(condition, req_action, OutValence) %>%
  summarise(
    mean_correct = mean(correct),
    sd_correct = sd(correct),
    count = n(),
    se_correct =sd_correct/sqrt(ppts),
  ) %>%
  na.omit()


# Create a ggplot with error bars, bars, and facets <- i think pirate plot in line 541 better!!!!!
ggplot(summary_data, aes(x = condition, y = mean_correct, ymin = mean_correct - se_correct, ymax = mean_correct + se_correct, fill = condition)) +
  geom_errorbar(position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +
  geom_text(aes(label = round(mean_correct, 2)), vjust = -0.5, position = position_dodge(width = 0.75)) +
  facet_grid(req_action ~ OutValence) +
  theme_APA




# 5. add points to the above 

# Merge summary_data and tus data
merged_data <- merge(tus, summary_data, by = "condition", all.x = TRUE) #merging should be a left join. In a left join, all rows from the left data frame (tus in this case) will be retained, and matching rows from the right data frame (summary_data) will be added. If there are no matches, the columns from the right data frame will contain missing values (NA).
merged_data <- merged_data %>% na.omit()


# Calculate the minimum and maximum y-values in your data
            #y_min <- min(summary_data$mean_correct - summary_data$se_correct)
            #y_max <- max(summary_data$mean_correct + summary_data$se_correct)

# Create a ggplot with error bars, bars, data points, and facets
ggplot(data = summary_data, aes(x = condition, y = mean_correct, fill = condition)) +
  geom_errorbar(aes(ymin = mean_correct - se_correct, ymax = mean_correct + se_correct),
                position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +

  # Use merged_data for geom_point instead of tus
  geom_point(data = merged_data, aes(x = condition, y = mean_correct, color = condition),
             position = position_dodge(width = 0.75), size = 1)+
  geom_text(aes(label = round(mean_correct, 3)), vjust = -0.5, position = position_dodge(width = 0.75)) +
  facet_grid(req_action ~ OutValence) +  
  theme_APA +
  # Set y-axis limits dynamically based on data
                #ylim(y_min, y_max)
  coord_cartesian(ylim=c(0.30,1))




# 6. YET ANOTHET PIRATE PLOT,                            -->i think that is the best for accuracy per all (named: Acc_perall5)
# Filter the data to exclude values outside the desired y-axis range
tus_filtered <- tus_correct %>% filter(correct >= 0.40 & correct <= 1)

#pirate plot
pirateplot(formula = correct ~ condition  + req_action +OutValence,
           data = tus_filtered,
                           theme = 0,
           #main = "Fully customized pirateplot",
           #pal = "southpark", # southpark color palette
           bean.f.o = .6, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+theme_APA
           #coord_cartesian(ylim=c(0.30,0.9))


```

#presses and no_presses means - needs work to be facet by response
```{r}
# Convert "response" to binary numeric variable
tus_numeric <- tus %>%
  mutate(response_numeric = as.numeric(response == "press"))  # Convert "press" to 1, "no_press" to 0


# Calculate mean number of presses and standard error per condition, cue, and response
summary_data <- tus_numeric %>%
  group_by(condition, Cue, response) %>%
  summarise(mean_response = mean(response_numeric, na.rm = TRUE),
            se_response = sqrt(mean_response * (1 - mean_response) / n()), na.rm = TRUE)

# Print summary data
summary_data
# Plot
ggplot(summary_data, aes(x = Cue, y = mean_response, fill = condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_response - se_response, ymax = mean_response + se_response),
                position = position_dodge(width = 0.9), width = 0.25) +
  labs(x = "Cue", y = "Mean Presses", title = "Mean Number of Presses per Condition and Cue") +
  facet_wrap(~ response, scales = "free_y") +  # Facet by response
  theme_minimal()



```



              ## I THINK I DO NOT NEED THIS CHUNK

#presses for correct  and presses for incorrect (nogos) - ***SEE COMMENTS FOR FURTHER EXPLANATION*** ALSO
         ****IMPORTANT FOR THE GW FOR THE AI****
```{r}
#means - PRESSES FOR GOs (that is pressed when they supposed to be pressing or else pressed for the Go conditions)

presses_for_correct <- subset(tus, response != "no_press"& correct == "1") # that is for both Goes (GW and GAL)
  press_mean_ID<-presses_for_correct %>% group_by(ID, OutValence, condition, req_action) %>% count(correct = "1")%>%summarize (n=mean(n))
  press_mean_cr  <- press_mean_ID %>% group_by(OutValence, condition, req_action)%>%summarize (n=mean(n))
  
pirateplot(formula = n ~ condition  + req_action + OutValence,
           main = "presses for GAL(left) and GW (right)",
             data = press_mean_cr,
           theme = 2,
           bar.f.o = .5,
           ylim = c(0, 80),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.5, # Inference fill
                  inf.b.o = 0.5, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "black",
                  point.cex = 1) #For GW, when AI was stimulated. participants pressed 
``` 


## How about RTs? ***NB COULD YOU CHECK PLEASE????***

```{r}

# 1. Calculate summary statistics (mean and standard deviation)     --> not so good
######NB do it per participant - the dots not all RTs in the plot)
      #filter data to exclude very high values
 filtered_data_rt <- tus %>%filter(RT >= 300, RT <= 1500)

pirateplot(formula = RT ~ condition  + req_action +OutValence,
           data = filtered_data_rt,
                           theme = 0,
           #main = "Fully customized pirateplot",
           #pal = "southpark", # southpark color palette
           bean.f.o = .2, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+theme_APA


# 2. compute mean_rt for each participant - ?????????not sure if this is OK - i might ignore it
Meanrtpersub_rt <- tus %>% group_by(ID, req_action, OutValence, condition, RT) %>% summarise(mean_rt_per_Subject = mean(RT))
Meanrtpersub_rt <- na.omit(Meanrtpersub_rt)
Meanrtpersub_rt <- Meanrtpersub_rt %>% group_by(req_action, OutValence, condition) %>% summarise(mean_rt_per_Subject = mean(mean_rt_per_Subject))

pirateplot(formula =  mean_rt_per_Subject ~ condition  + req_action +OutValence,
           data = Meanrtpersub_rt,
                           theme = 0,
           #main = "mean_RT_per_SUB",
           #pal = "southpark", # southpark color palette
           bean.f.o = .2, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+theme_APA



#  3. AND with full tus !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1TO CHECK WHEN I ADD TRIAL COUNT AND BLOCK CHANGES LOADS. ask NADEIGE :-)
Meanrtpersub_rt2 <- tus %>% group_by(ID, Cue, req_action, OutValence,  condition, RT) %>% summarise(mean_rt = mean(RT))
Meanrtpersub_rt2 <- na.omit(Meanrtpersub_rt2) # group by extra :block, TrialCount,


summary_data_rt <- Meanrtpersub_rt2 %>%
  group_by(condition, req_action, OutValence) %>%
  summarise(
    mean_rt = mean(RT),
    sd_rt = sd(RT),  # Calculate the standard deviation of RT
    count = n(),
    se_rt = sd_rt / sqrt(ppts)  # Calculate the standard error
  ) %>%
  na.omit()

# Create a ggplot with error bars, bars, and facets - pirate plot in the beginning is better (for RTs) - line 286 
ggplot(summary_data_rt, aes(x = condition, y = mean_rt, ymin = mean_rt - se_rt, ymax = mean_rt + se_rt, fill = condition)) +
  geom_errorbar(position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +
  geom_text(aes(label = round(mean_rt, 2)), vjust = -0.5, position = position_dodge(width = 0.75)) +
 facet_grid(req_action ~ OutValence) +
theme_APA

 # 4. as above - adding data points
        #Merge summary_data and tus data 
merged_data_rt <- merge(tus, summary_data_rt, by = "condition", all.x = TRUE) 
              #merged_data_rt <- merged_data_rt %>% na.omit()

# Create a ggplot with error bars, bars, data points, and facets
ggplot(data = summary_data_rt, aes(x = condition, y = mean_rt, fill = condition)) +
  geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt),
                position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +

  # Use merged_data for geom_point instead of tus
  geom_point(data = merged_data_rt, aes(x = condition, y = mean_rt, color = condition),
             position = position_dodge(width = 0.75), size = 2, alpha = 0.5) +
  geom_text(aes(label = round(mean_rt, 3)), vjust = -0.5, position = position_dodge(width = 0.75)) +
  facet_grid(req_action ~ OutValence) +
  theme_APA
```


## performance per participant
```{r}
#summary - correct Cues
ggplot(tus,
       aes(x=Cue, y= correct, color = Cue, fill= Cue)) + 
  geom_bar(stat = "identity")

#correct counts per Cue
ccc<-tus %>% group_by (Cue)%>% count (correct);View (ccc)

#correct counts per Cue per ID
ccc_id<-tus %>% group_by (Cue, ID)%>% count (correct);View (ccc_id)

#correct per ID
c<-tus %>% filter(correct == "1")%>% group_by (ID)%>% count (correct);c

#response per ID
response_per_ppt <-tus %>% group_by (ID)%>% count (response);View (response_per_ppt)

mean(c$n) #avg of 294 correct responses--> 
          #may be if a person has less than 230 or 210? correct responses --> CUT? or below 53? see below aggregate
```


   
   
#proportion of RT response per type of Stimulation (sham, ai, dACC) 
```{r}
#trial_by_trial behaviour RT 


#for all

# compute proportion of go responses for each participant (first sum per ID, then feed that into general summary)
MeanRTpersub <- tus %>% group_by(ID, Cue, req_action, OutValence, block, TrialCount) %>% summarise(meanRT = mean(RT))

MeanRT <- MeanRTpersub %>% group_by(Cue, req_action, OutValence, block,  TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot of p(Go) responses 
ggplot(MeanRT) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_RT") +
  xlim (0,20) +theme_bw() 
#plot of RT per block
ggplot(MeanRT) + 
  geom_smooth(aes(TrialCount,meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  facet_grid(~block)+
  theme_bw() +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_RT_perBlock") +
  xlim(0, 20)





#AI - 
ai <- subset(tus, condition == "c.ai")

MeanRTpesppersub_ai <- ai %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(RT))

MeanRTResp.ai <- MeanRTpesppersub_ai %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot
ai_avg<- ggplot(MeanRTResp.ai) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for AI_RT") +
   xlim(NA, 20)+
 theme_bw() 


    #dACC - 
dacc <- subset(tus, condition == "b.dacc")
#dacc <- na.omit(dacc)

# compute proportion of go responses for each participant
MeanRTpesppersub_dacc <- dacc %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(RT))
MeanRTpersp.dacc <- MeanRTpesppersub_dacc %>% group_by(Cue, req_action, OutValence, TrialCount ) %>% summarise(meanRT = mean(meanRT))

#plot
dacc_avg<- ggplot(MeanRTpersp.dacc) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for dACC_RT")+
   xlim(NA, 20)+ theme_bw() 



    #Sham
sham <- subset(tus, condition == "a.sham")

# compute proportion of go responses for each participant
MeanRTpersub_sham <- sham %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(RT))

MeanRTResp.sham <- MeanRTpersub_sham %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot
sham_avg<- ggplot(MeanRTResp.sham) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for sham_RT") +
   xlim(NA, 20)+
 theme_bw() 

#roll avg per CONDITION
avg_rt <- ggarrange(sham_avg, ai_avg, dacc_avg,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);avg_rt
```

   
   
   
   
   ## RTrolling average per CUE for all three conditions (plot with NGW for three conditions (sham, ai, dACC), plot GW..etc.)

```{r}
#Grey area is CI

#GW
GW <- subset(tus, Cue == "GW")

# compute proportion of go responses for each participant
MeanRTpersub_gw <- GW %>% group_by(ID, req_action, OutValence, TrialCount, condition) %>% summarise(meanRT = mean(RT))
MeanRTpersub_gw <- na.omit(MeanRTpersub_gw)
MeanRTResp_gw <- MeanRTpersub_gw %>% group_by(req_action, OutValence, TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot######################play with lines
GW_rt<-ggplot(data=MeanRTResp_gw, mapping =aes(TrialCount, meanRT, colour=condition)) + 
  geom_smooth(linetype = "longdash", alpha = 0.3) +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
  ylim(0, 650)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_GW_RT") +theme_bw() 

#GAL
GAL <- subset(tus, Cue == "GAL")

# compute proportion of go responses for each participant
MeanRTpersub_gal <- GAL %>% group_by(ID, TrialCount, condition) %>% summarise(meanRT = mean(RT))
MeanRTpersub_gal <- na.omit(MeanRTpersub_gal)
MeanRTResp_gal <- MeanRTpersub_gal %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot
GAL_rt<-ggplot(data=MeanRTResp_gal, mapping =aes(TrialCount, meanRT, colour=condition)) + 
  geom_smooth(linetype = "longdash", alpha = 0.3) +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0, 650)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_GAL_RT") +theme_bw() 

#NGW
NGW <- subset(tus, Cue == "NGW")

# compute proportion of go responses for each participant
MeanRTpersub_NGW <- NGW %>% group_by(ID, TrialCount, condition) %>% summarise(meanRT = mean(RT))
MeanRTpersub_NGW <- na.omit(MeanRTpersub_NGW)
MeanRTResp_NGW <- MeanRTpersub_NGW %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot - need to work on linetype
NGW_rt<-ggplot(MeanRTResp_NGW) + 
  geom_smooth(aes(TrialCount, meanRT, colour=condition), size = 1)  +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0,650)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_NGW_RT") +theme_bw() 



#NGL
NGL <- subset(tus, Cue == "NGL")

# compute proportion of go responses for each participant
MeanRTpersub_NGL <- NGL %>% group_by(ID, TrialCount, condition) %>% summarise(meanRT = mean(RT))
MeanRTpersub_NGL <- na.omit(MeanRTpersub_NGL)
MeanRTResp_NGL <- MeanRTpersub_NGL %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot
NGL_rt<-ggplot(MeanRTResp_NGL) + 
  geom_smooth(aes(TrialCount, meanRT, colour=condition ), size = 1)  +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
      coord_cartesian(ylim = c(0, 650))+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_NGL_RT") + theme_bw() 



#CUES PER CONDITION RT
cues_rt <- ggarrange(GW_rt, GAL_rt, NGW_rt, NGL_rt,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);cues_rt
   #ylim(0.05, 0.9); 
```

   
   
   
   
   
   

## PROPORTIONs - correct PER PARTCIPANT
```{r}
#the proportion of 1s by participant, + more i.e. sound, and language.
#Because the proportion of 1s in a vector with only 0s and 1s is just the mean, this should work:

df <- aggregate(data=tus, correct ~ ID, FUN="mean")#fun = mean #https://r-coder.com/aggregate-r/
p <- ggplot(df)
p <- p + geom_bar(mapping=aes(x=correct, y=ID), stat='identity')+
  geom_vline(xintercept = 0.53, col = "red")+ 
  geom_vline(xintercept = 0.50, col = "grey")+
   geom_vline(xintercept = 0.80, col = "green")+
  geom_text(aes(x=0.54, label="53%", y=4), colour="black", angle=90) +
geom_text(aes(x=0.49, label="50%", y=9), colour="black", angle=90)+
  geom_text(aes(x=0.79, label="80%", y=6), colour="black", angle=90) 
p + ylab('ID')

#same as above but with stat_summary
ggplot(tus) + 
  stat_summary(aes(x = ID, y = correct), 
               geom = "bar")

#performance per participant and condition
aggregate(data=tus, correct ~ ID+condition, FUN="mean") #fun = mean #https://r-coder.com/aggregate-r/

df_c <- aggregate(data=tus, correct ~ ID +condition, FUN="mean")
 
ggplot(data = df_c) + 
  geom_bar(mapping = aes(fill = condition, x = ID, y = correct), stat = "identity", position = "dodge")

#same but with lines and dots
 df_c %>%ggplot(aes(condition, correct, color=ID)) +
   #geom_boxplot()+
  geom_point(aes(fill=ID),size=5) +
 # scale_x_log10()+
  geom_line(aes(group = ID),color="grey")
#ggsave("#performance per participant and condition.png")


#performance per  condition - awful
aggregate(data=tus, correct ~ condition, FUN="mean") #fun = mean #https://r-coder.com/aggregate-r/

df_con <- aggregate(data=tus, correct ~ condition, FUN="mean")
 
ggplot(data = df_con) + 
  geom_bar(mapping = aes(fill = condition, x = condition, y = correct), stat = "identity", position = "dodge")
```
 
 ## RTs for participants 
```{r}

#the proportion of 1s by participant, + more i.e. sound, and language.
#Because the proportion of 1s in a vector with only 0s and 1s is just the mean, this should work:

df <- aggregate(data=tus, RT ~ ID, FUN="mean")#fun = mean #https://r-coder.com/aggregate-r/
p <- ggplot(df)
p <- p + geom_bar(mapping=aes(x=RT, y=ID), stat='identity')+
  geom_vline(xintercept = 150, col = "red")+ 
  geom_vline(xintercept = 300, col = "grey")+
   geom_vline(xintercept = 400, col = "green")+
  geom_text(aes(x=150, label="150", y=12), colour="black", angle=90) +
geom_text(aes(x=300, label="300", y=9), colour="black", angle=90)+
  geom_text(aes(x=400, label="400", y=6), colour="black", angle=90) 
p + ylab('ID')


#rt per participant per condition
aggregate(data=tus, RT ~ ID+condition, FUN="mean") #fun = mean #https://r-coder.com/aggregate-r/

df_rt <- aggregate(data=tus, RT ~ ID +condition, FUN="mean")
 
ggplot(data = df_rt) + 
  geom_bar(mapping = aes(fill = condition, x = ID, y = RT), stat = "identity", position = "dodge") 
  

#same but with lines and dots
  df_rt %>%ggplot(aes(condition, RT, color=ID)) +
   #geom_boxplot()+
  geom_point(aes(fill=ID),size=5) +
 #scale_x_log10()+
  geom_line(aes(group = ID),color="grey")
  
#-------------------------------
  
  #for GW only (correct) - NO POINT
 # gwin <- subset(tus, Cue == "GW")

#  gwin_cr <- aggregate(data=gwin, correct ~ ID +condition, FUN="mean")

#gwin_cr %>%ggplot(aes(condition, correct, color=ID)) +
                            #geom_boxplot()+
 # geom_point(aes(fill=ID),size=5) +
                        #scale_x_log10()+
  #geom_line(aes(group = ID),color="grey")


  #for NGW only (RT) - NO POINT

#gwin_rt <- aggregate(data=gwin, RT ~ ID +condition, FUN="mean")

#gwin_rt %>%ggplot(aes(condition, RT, color=ID)) +
             #geom_boxplot()+
  #geom_point(aes(fill=ID),size=5) +
                #scale_x_log10()+
  #geom_line(aes(group = ID),color="grey")
```



##FOLLOW UP BEHAVIOUR GENERAL FEEDBACK
```{r}

                         #general followup beha - LOOKS CORRECT

   #Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Create a grouped bar plot showing the distribution of follow-up behaviors after each type of feedback
ggplot(feedback_data, aes(x = feedback, fill = followup_beha)) +
  geom_bar(position = "dodge", color = "black", stat = "count") +
  labs(title = "Response Distribution after Different Types of Feedback",
       x = "Feedback", y = "Count") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal()






                                  #accuracy

# A# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
accuracy_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "correct", "condition"))

# Exclude NA values
accuracy_data <- na.omit(accuracy_data)

# Create a grouped bar plot showing the mean of correct responses after each type of feedback for accuracy
# Check the range of the 'correct' variable
summary(accuracy_data$correct)

# Assuming the minimum value is 0.25 or greater, set the y-axis limits using coord_cartesian
ggplot(accuracy_data, aes(x = feedback, fill = followup_beha, y = correct)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Correct Responses after Different Types of Feedback (Accuracy)",
       x = "Feedback", y = "Mean Correct Response") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  #facet_grid(~condition)+
  coord_cartesian(ylim = c(0.2, 1))




       #mean condition accuracy
# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "condition", "correct"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Calculate the mean of 'correct' per condition
accuracy_data <- aggregate(correct ~ feedback + followup_beha + condition, data = feedback_data, FUN = mean)

# Create a grouped bar plot showing the mean of correct responses after each type of feedback, separated by condition
ggplot(accuracy_data, aes(x = feedback, y = correct, fill = followup_beha)) +
  geom_bar(position = "dodge", color = "black", stat = "identity") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Mean Correct Responses after Different Types of Feedback by Condition",
       x = "Feedback", y = "Mean Correct Response") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal() +
  coord_cartesian(ylim = c(0.3, 1)) # Set the y-axis limits


  
                                  #mean RT

#A# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
rt_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "RT"))

# Exclude NA values
rt_data <- na.omit(rt_data)

# Create a grouped bar plot showing the mean of reaction times after each type of feedback for RT
ggplot(rt_data, aes(x = feedback, fill = followup_beha, y = RT)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Reaction Time after Different Types of Feedback (RT)",
       x = "Feedback", y = "Mean Reaction Time") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal()+
  coord_cartesian(ylim = c(0, 600))




                          #mean per condition for the followup_beha - not stacked [KEEP]

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, and condition
count_data <- feedback_data %>%
  group_by(feedback, followup_beha, condition) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback and condition
total_counts <- count_data %>%
  group_by(feedback, condition) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data <- count_data %>%
  left_join(total_counts, by = c("feedback", "condition"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback and condition
mean_proportion <- count_data %>%
  mutate(mean_proportion = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition
ggplot(mean_proportion, aes(x = feedback, y = mean_proportion, fill = followup_beha)) +
  geom_bar(position = "dodge", stat = "identity") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Mean Proportion of Response after Different Types of Feedback by Condition",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks


  
 #countS per condition - stacked [KEEP]

# Count occurrences of press and no_press per condition
press_counts <- feedback_data %>%
  group_by(feedback, condition, followup_beha) %>%
  summarise(count = n()) %>%
  pivot_wider(names_from = followup_beha, values_from = count, values_fill = 0)

# Calculate the mean of press and no_press responses per condition
mean_press <- press_counts %>%
  group_by(condition) %>%
  summarise(mean_press = mean(press),
            mean_no_press = mean(no_press))

# Plot counts of "press" and "no_press" per condition
ggplot(press_counts, aes(x = feedback)) +
  geom_bar(aes(y = press, fill = "Press"), stat = "identity", position = "dodge", color = "black", show.legend = TRUE) +
  geom_bar(aes(y = no_press, fill = "No Press"), stat = "identity", position = "dodge", color = "black", show.legend = TRUE) +
  facet_wrap(~ condition, scales = "free") +
  labs(title = "Counts of 'press' and 'no_press' per Condition",
       x = "Feedback", y = "Count") +
  scale_fill_manual(values = custom_colors,
                    guide = guide_legend(title = "Follow-Up Behavior", 
                                         labels = c("Press", "No Press"))) +
  theme_minimal() +
  theme(legend.position = "right")





#same as above but just counts

  #count second one is better for count
# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "condition", "Cue"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Create a grouped bar plot showing the distribution of responses after each type of feedback, separated by condition
ggplot(feedback_data, aes(x = feedback, fill = followup_beha)) +
  geom_bar(position = "dodge", color = "black", stat = "count") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Response Distribution after Different Types of Feedback by Condition",
       x = "Feedback", y = "Count") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal()+
  coord_cartesian(ylim = c(0, 2500))
```

   # foolow_up beha per cue interesting
```{r}
# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus, feedback %in% c("win", "lose", "neutral"), 
                        select = c("feedback", "followup_beha", "condition", "Cue"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Filter data for "GW" and "GAL" cues
feedback_data <- feedback_data %>%
  filter(Cue %in% c("GW", "GAL"))

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, condition, and Cue
count_data <- feedback_data %>%
  group_by(feedback, followup_beha, condition, Cue) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback, condition, and Cue
total_counts <- count_data %>%
  group_by(feedback, condition, Cue) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data <- count_data %>%
  left_join(total_counts, by = c("feedback", "condition", "Cue"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback, condition, and Cue
mean_proportion <- count_data %>%
  mutate(mean_proportion = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition and Cue
ggplot(mean_proportion, aes(x = feedback, y = mean_proportion, fill = followup_beha)) +
  geom_bar(position = "dodge", stat = "identity") +
  facet_grid(Cue ~ condition) +  # Facet by condition and Cue
  labs(title = "Mean Proportion of Response after Different Types of Feedback by Condition and Cue",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks



```








##FOLLOW UP BEHAVIOUR CORRECT FEEDBACK

```{r}

   #Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data_r <- subset(tus, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_response", "condition"))

# Exclude NA values
feedback_data_r <- na.omit(feedback_data_r)

              #mean per condition for the followup_beha - not stacked [KEEP]

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, and condition
count_data_r <- feedback_data_r %>%
  group_by(feedback, followup_response, condition) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback and condition
total_counts_r <- count_data_r %>%
  group_by(feedback, condition) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data_r <- count_data_r %>%
  left_join(total_counts_r, by = c("feedback", "condition"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback and condition
mean_proportion_r <- count_data_r %>%
  mutate(mean_proportion_r = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition
ggplot(mean_proportion_r, aes(x = feedback, y = mean_proportion_r, fill = followup_response)) +
  geom_bar(position = "dodge", stat = "identity") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Mean Proportion of Response after Different Types of Feedback by Condition",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.65), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks





             #[per cue]

# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data_rcue <- subset(tus, feedback %in% c("win", "lose", "neutral"), 
                        select = c("feedback", "followup_response", "condition", "Cue"))

# Exclude NA values
feedback_data_rcue <- na.omit(feedback_data_rcue)

# Filter data for "GW" and "GAL" cues
feedback_data_rcue <- feedback_data_rcue %>%
  filter(Cue %in% c("GW"))

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, condition, and Cue
count_data_rcue <- feedback_data_rcue %>%
  group_by(feedback, followup_response, condition, Cue) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback, condition, and Cue
total_counts_rcue <- count_data_rcue %>%
  group_by(feedback, condition, Cue) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data_rcue <- count_data_rcue %>%
  left_join(total_counts, by = c("feedback", "condition", "Cue"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback, condition, and Cue
mean_proportion_rcue <- count_data_rcue %>%
  mutate(mean_proportion_rcue = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition and Cue
ggplot(mean_proportion_rcue, aes(x = feedback, y = mean_proportion_rcue, fill = followup_response)) +
  geom_bar(position = "dodge", stat = "identity") +
  facet_grid(Cue ~ condition) +  # Facet by condition and Cue
  labs(title = "Mean Proportion of Response after Different Types of correct Feedback by Condition and Cue",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "#66c2a5", "no_press" = "#fc8d62")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.4), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks




```




ALSO DO

-	a) follow up behaviour after unsuccessfull stop (pressed while a noGo) and 
-	b) follow up behaviour after positive or after correct feedback (80% of the cases, as the other 20% was a random opposite feedback). !!!--.> 

Cai and colleagues (2014): (1) rAI and salience networks may contribute to inhibitory control by detecting salient stopping events; 
- c) Go Cues behaviour (there is something going on in my data for sure, and (2) rAI and salience networks may directly recruit inhibition by slowing down responses after salient events 
- d) RTs followup after positive or negative feedback maybe, found for WIN only? WHAT ARE MY SALIENT QUES? I AM CONFUSED order of saliency? GW, NGW, GAL, NGL (or the very first three more salient than NGL)? As, GW and NGW more salient that is why AI significant and GW more presses for AI? 
-	E) follow up after positive and negative feedback only	
-	
